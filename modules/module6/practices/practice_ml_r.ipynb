{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicing Machine Learning with Naïve Bayes\n",
    "\n",
    "So we should be familiar with the major components involved in classification. But we still need to cover how to do Naïve Bayes in `R`. Much like the `Python` exercise, we are going to learn how to create a training and testing set, as well using feature selection to prune reduce the number of features that go into our model.\n",
    "\n",
    "It begins by loading in the appropriate library. Again, there are several libraries that have a Naïve Bayesian classifier built in, but today we are going to be using `e1071`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(e1071)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will begin this notebook like many of the notebooks before it, by looking at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th><th scope=col>Species</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>5.1   </td><td>3.5   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.9   </td><td>3.0   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.7   </td><td>3.2   </td><td>1.3   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.6   </td><td>3.1   </td><td>1.5   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>5.0   </td><td>3.6   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>5.4   </td><td>3.9   </td><td>1.7   </td><td>0.4   </td><td>setosa</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species\\\\\n",
       "\\hline\n",
       "\t 5.1    & 3.5    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 4.9    & 3.0    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 4.7    & 3.2    & 1.3    & 0.2    & setosa\\\\\n",
       "\t 4.6    & 3.1    & 1.5    & 0.2    & setosa\\\\\n",
       "\t 5.0    & 3.6    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 5.4    & 3.9    & 1.7    & 0.4    & setosa\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n",
       "1 5.1          3.5         1.4          0.2         setosa \n",
       "2 4.9          3.0         1.4          0.2         setosa \n",
       "3 4.7          3.2         1.3          0.2         setosa \n",
       "4 4.6          3.1         1.5          0.2         setosa \n",
       "5 5.0          3.6         1.4          0.2         setosa \n",
       "6 5.4          3.9         1.7          0.4         setosa "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `Python` practice notebook, we discussed the importance of splitting our data in to training and testing sets. We are going to do the same thing with `R` before we train our model. The method is very similar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th><th scope=col>Species</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>40</th><td>5.1       </td><td>3.4       </td><td>1.5       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>56</th><td>5.7       </td><td>2.8       </td><td>4.5       </td><td>1.3       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>85</th><td>5.4       </td><td>3.0       </td><td>4.5       </td><td>1.5       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>134</th><td>6.3       </td><td>2.8       </td><td>5.1       </td><td>1.5       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>30</th><td>4.7       </td><td>3.2       </td><td>1.6       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>131</th><td>7.4       </td><td>2.8       </td><td>6.1       </td><td>1.9       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>137</th><td>6.3       </td><td>3.4       </td><td>5.6       </td><td>2.4       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>95</th><td>5.6       </td><td>2.7       </td><td>4.2       </td><td>1.3       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>90</th><td>5.5       </td><td>2.5       </td><td>4.0       </td><td>1.3       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>4.4       </td><td>2.9       </td><td>1.4       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>29</th><td>5.2       </td><td>3.4       </td><td>1.4       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>25</th><td>4.8       </td><td>3.4       </td><td>1.9       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>143</th><td>5.8       </td><td>2.7       </td><td>5.1       </td><td>1.9       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>53</th><td>6.9       </td><td>3.1       </td><td>4.9       </td><td>1.5       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>105</th><td>6.5       </td><td>3.0       </td><td>5.8       </td><td>2.2       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>68</th><td>5.8       </td><td>2.7       </td><td>4.1       </td><td>1.0       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>97</th><td>5.7       </td><td>2.9       </td><td>4.2       </td><td>1.3       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>132</th><td>7.9       </td><td>3.8       </td><td>6.4       </td><td>2.0       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>51</th><td>7.0       </td><td>3.2       </td><td>4.7       </td><td>1.4       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>102</th><td>5.8       </td><td>2.7       </td><td>5.1       </td><td>1.9       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>122</th><td>5.6       </td><td>2.8       </td><td>4.9       </td><td>2.0       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>28</th><td>5.2       </td><td>3.5       </td><td>1.5       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>84</th><td>6.0       </td><td>2.7       </td><td>5.1       </td><td>1.6       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>5.7       </td><td>4.4       </td><td>1.5       </td><td>0.4       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>34</th><td>5.5       </td><td>4.2       </td><td>1.4       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>49</th><td>5.3       </td><td>3.7       </td><td>1.5       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>4.9       </td><td>3.0       </td><td>1.4       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>48</th><td>4.6       </td><td>3.2       </td><td>1.4       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>107</th><td>4.9       </td><td>2.5       </td><td>4.5       </td><td>1.7       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>42</th><td>4.5       </td><td>2.3       </td><td>1.3       </td><td>0.3       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><th scope=row>71</th><td>6.4       </td><td>2.8       </td><td>5.6       </td><td>2.1       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>72</th><td>5.6       </td><td>3.0       </td><td>4.5       </td><td>1.5       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>73</th><td>5.7       </td><td>2.6       </td><td>3.5       </td><td>1.0       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>74</th><td>5.0       </td><td>3.0       </td><td>1.6       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>75</th><td>5.5       </td><td>3.5       </td><td>1.3       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>76</th><td>6.0       </td><td>2.9       </td><td>4.5       </td><td>1.5       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>77</th><td>6.9       </td><td>3.1       </td><td>5.1       </td><td>2.3       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>78</th><td>6.7       </td><td>3.1       </td><td>4.7       </td><td>1.5       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>79</th><td>5.1       </td><td>2.5       </td><td>3.0       </td><td>1.1       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>80</th><td>6.2       </td><td>2.2       </td><td>4.5       </td><td>1.5       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>81</th><td>4.8       </td><td>3.1       </td><td>1.6       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>82</th><td>7.1       </td><td>3.0       </td><td>5.9       </td><td>2.1       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>83</th><td>6.7       </td><td>3.0       </td><td>5.0       </td><td>1.7       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>84</th><td>7.3       </td><td>2.9       </td><td>6.3       </td><td>1.8       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>85</th><td>5.5       </td><td>2.4       </td><td>3.8       </td><td>1.1       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>86</th><td>4.3       </td><td>3.0       </td><td>1.1       </td><td>0.1       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>87</th><td>6.5       </td><td>3.2       </td><td>5.1       </td><td>2.0       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>88</th><td>5.0       </td><td>3.4       </td><td>1.5       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>89</th><td>6.2       </td><td>2.8       </td><td>4.8       </td><td>1.8       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>90</th><td>6.7       </td><td>3.1       </td><td>5.6       </td><td>2.4       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>91</th><td>5.8       </td><td>4.0       </td><td>1.2       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>92</th><td>4.6       </td><td>3.1       </td><td>1.5       </td><td>0.2       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>93</th><td>7.2       </td><td>3.6       </td><td>6.1       </td><td>2.5       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>94</th><td>6.7       </td><td>3.1       </td><td>4.4       </td><td>1.4       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>95</th><td>5.0       </td><td>3.5       </td><td>1.6       </td><td>0.6       </td><td>setosa    </td></tr>\n",
       "\t<tr><th scope=row>96</th><td>7.7       </td><td>2.6       </td><td>6.9       </td><td>2.3       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>97</th><td>6.0       </td><td>3.0       </td><td>4.8       </td><td>1.8       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>98</th><td>6.7       </td><td>3.3       </td><td>5.7       </td><td>2.5       </td><td>virginica </td></tr>\n",
       "\t<tr><th scope=row>99</th><td>6.2       </td><td>2.9       </td><td>4.3       </td><td>1.3       </td><td>versicolor</td></tr>\n",
       "\t<tr><th scope=row>100</th><td>6.3       </td><td>3.3       </td><td>6.0       </td><td>2.5       </td><td>virginica </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species\\\\\n",
       "\\hline\n",
       "\t40 & 5.1        & 3.4        & 1.5        & 0.2        & setosa    \\\\\n",
       "\t56 & 5.7        & 2.8        & 4.5        & 1.3        & versicolor\\\\\n",
       "\t85 & 5.4        & 3.0        & 4.5        & 1.5        & versicolor\\\\\n",
       "\t134 & 6.3        & 2.8        & 5.1        & 1.5        & virginica \\\\\n",
       "\t30 & 4.7        & 3.2        & 1.6        & 0.2        & setosa    \\\\\n",
       "\t131 & 7.4        & 2.8        & 6.1        & 1.9        & virginica \\\\\n",
       "\t137 & 6.3        & 3.4        & 5.6        & 2.4        & virginica \\\\\n",
       "\t95 & 5.6        & 2.7        & 4.2        & 1.3        & versicolor\\\\\n",
       "\t90 & 5.5        & 2.5        & 4.0        & 1.3        & versicolor\\\\\n",
       "\t9 & 4.4        & 2.9        & 1.4        & 0.2        & setosa    \\\\\n",
       "\t29 & 5.2        & 3.4        & 1.4        & 0.2        & setosa    \\\\\n",
       "\t25 & 4.8        & 3.4        & 1.9        & 0.2        & setosa    \\\\\n",
       "\t143 & 5.8        & 2.7        & 5.1        & 1.9        & virginica \\\\\n",
       "\t53 & 6.9        & 3.1        & 4.9        & 1.5        & versicolor\\\\\n",
       "\t105 & 6.5        & 3.0        & 5.8        & 2.2        & virginica \\\\\n",
       "\t68 & 5.8        & 2.7        & 4.1        & 1.0        & versicolor\\\\\n",
       "\t97 & 5.7        & 2.9        & 4.2        & 1.3        & versicolor\\\\\n",
       "\t132 & 7.9        & 3.8        & 6.4        & 2.0        & virginica \\\\\n",
       "\t51 & 7.0        & 3.2        & 4.7        & 1.4        & versicolor\\\\\n",
       "\t102 & 5.8        & 2.7        & 5.1        & 1.9        & virginica \\\\\n",
       "\t122 & 5.6        & 2.8        & 4.9        & 2.0        & virginica \\\\\n",
       "\t28 & 5.2        & 3.5        & 1.5        & 0.2        & setosa    \\\\\n",
       "\t84 & 6.0        & 2.7        & 5.1        & 1.6        & versicolor\\\\\n",
       "\t16 & 5.7        & 4.4        & 1.5        & 0.4        & setosa    \\\\\n",
       "\t34 & 5.5        & 4.2        & 1.4        & 0.2        & setosa    \\\\\n",
       "\t49 & 5.3        & 3.7        & 1.5        & 0.2        & setosa    \\\\\n",
       "\t2 & 4.9        & 3.0        & 1.4        & 0.2        & setosa    \\\\\n",
       "\t48 & 4.6        & 3.2        & 1.4        & 0.2        & setosa    \\\\\n",
       "\t107 & 4.9        & 2.5        & 4.5        & 1.7        & virginica \\\\\n",
       "\t42 & 4.5        & 2.3        & 1.3        & 0.3        & setosa    \\\\\n",
       "\t⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t71 & 6.4        & 2.8        & 5.6        & 2.1        & virginica \\\\\n",
       "\t72 & 5.6        & 3.0        & 4.5        & 1.5        & versicolor\\\\\n",
       "\t73 & 5.7        & 2.6        & 3.5        & 1.0        & versicolor\\\\\n",
       "\t74 & 5.0        & 3.0        & 1.6        & 0.2        & setosa    \\\\\n",
       "\t75 & 5.5        & 3.5        & 1.3        & 0.2        & setosa    \\\\\n",
       "\t76 & 6.0        & 2.9        & 4.5        & 1.5        & versicolor\\\\\n",
       "\t77 & 6.9        & 3.1        & 5.1        & 2.3        & virginica \\\\\n",
       "\t78 & 6.7        & 3.1        & 4.7        & 1.5        & versicolor\\\\\n",
       "\t79 & 5.1        & 2.5        & 3.0        & 1.1        & versicolor\\\\\n",
       "\t80 & 6.2        & 2.2        & 4.5        & 1.5        & versicolor\\\\\n",
       "\t81 & 4.8        & 3.1        & 1.6        & 0.2        & setosa    \\\\\n",
       "\t82 & 7.1        & 3.0        & 5.9        & 2.1        & virginica \\\\\n",
       "\t83 & 6.7        & 3.0        & 5.0        & 1.7        & versicolor\\\\\n",
       "\t84 & 7.3        & 2.9        & 6.3        & 1.8        & virginica \\\\\n",
       "\t85 & 5.5        & 2.4        & 3.8        & 1.1        & versicolor\\\\\n",
       "\t86 & 4.3        & 3.0        & 1.1        & 0.1        & setosa    \\\\\n",
       "\t87 & 6.5        & 3.2        & 5.1        & 2.0        & virginica \\\\\n",
       "\t88 & 5.0        & 3.4        & 1.5        & 0.2        & setosa    \\\\\n",
       "\t89 & 6.2        & 2.8        & 4.8        & 1.8        & virginica \\\\\n",
       "\t90 & 6.7        & 3.1        & 5.6        & 2.4        & virginica \\\\\n",
       "\t91 & 5.8        & 4.0        & 1.2        & 0.2        & setosa    \\\\\n",
       "\t92 & 4.6        & 3.1        & 1.5        & 0.2        & setosa    \\\\\n",
       "\t93 & 7.2        & 3.6        & 6.1        & 2.5        & virginica \\\\\n",
       "\t94 & 6.7        & 3.1        & 4.4        & 1.4        & versicolor\\\\\n",
       "\t95 & 5.0        & 3.5        & 1.6        & 0.6        & setosa    \\\\\n",
       "\t96 & 7.7        & 2.6        & 6.9        & 2.3        & virginica \\\\\n",
       "\t97 & 6.0        & 3.0        & 4.8        & 1.8        & virginica \\\\\n",
       "\t98 & 6.7        & 3.3        & 5.7        & 2.5        & virginica \\\\\n",
       "\t99 & 6.2        & 2.9        & 4.3        & 1.3        & versicolor\\\\\n",
       "\t100 & 6.3        & 3.3        & 6.0        & 2.5        & virginica \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "    Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n",
       "40  5.1          3.4         1.5          0.2         setosa    \n",
       "56  5.7          2.8         4.5          1.3         versicolor\n",
       "85  5.4          3.0         4.5          1.5         versicolor\n",
       "134 6.3          2.8         5.1          1.5         virginica \n",
       "30  4.7          3.2         1.6          0.2         setosa    \n",
       "131 7.4          2.8         6.1          1.9         virginica \n",
       "137 6.3          3.4         5.6          2.4         virginica \n",
       "95  5.6          2.7         4.2          1.3         versicolor\n",
       "90  5.5          2.5         4.0          1.3         versicolor\n",
       "9   4.4          2.9         1.4          0.2         setosa    \n",
       "29  5.2          3.4         1.4          0.2         setosa    \n",
       "25  4.8          3.4         1.9          0.2         setosa    \n",
       "143 5.8          2.7         5.1          1.9         virginica \n",
       "53  6.9          3.1         4.9          1.5         versicolor\n",
       "105 6.5          3.0         5.8          2.2         virginica \n",
       "68  5.8          2.7         4.1          1.0         versicolor\n",
       "97  5.7          2.9         4.2          1.3         versicolor\n",
       "132 7.9          3.8         6.4          2.0         virginica \n",
       "51  7.0          3.2         4.7          1.4         versicolor\n",
       "102 5.8          2.7         5.1          1.9         virginica \n",
       "122 5.6          2.8         4.9          2.0         virginica \n",
       "28  5.2          3.5         1.5          0.2         setosa    \n",
       "84  6.0          2.7         5.1          1.6         versicolor\n",
       "16  5.7          4.4         1.5          0.4         setosa    \n",
       "34  5.5          4.2         1.4          0.2         setosa    \n",
       "49  5.3          3.7         1.5          0.2         setosa    \n",
       "2   4.9          3.0         1.4          0.2         setosa    \n",
       "48  4.6          3.2         1.4          0.2         setosa    \n",
       "107 4.9          2.5         4.5          1.7         virginica \n",
       "42  4.5          2.3         1.3          0.3         setosa    \n",
       "⋮   ⋮            ⋮           ⋮            ⋮           ⋮         \n",
       "71  6.4          2.8         5.6          2.1         virginica \n",
       "72  5.6          3.0         4.5          1.5         versicolor\n",
       "73  5.7          2.6         3.5          1.0         versicolor\n",
       "74  5.0          3.0         1.6          0.2         setosa    \n",
       "75  5.5          3.5         1.3          0.2         setosa    \n",
       "76  6.0          2.9         4.5          1.5         versicolor\n",
       "77  6.9          3.1         5.1          2.3         virginica \n",
       "78  6.7          3.1         4.7          1.5         versicolor\n",
       "79  5.1          2.5         3.0          1.1         versicolor\n",
       "80  6.2          2.2         4.5          1.5         versicolor\n",
       "81  4.8          3.1         1.6          0.2         setosa    \n",
       "82  7.1          3.0         5.9          2.1         virginica \n",
       "83  6.7          3.0         5.0          1.7         versicolor\n",
       "84  7.3          2.9         6.3          1.8         virginica \n",
       "85  5.5          2.4         3.8          1.1         versicolor\n",
       "86  4.3          3.0         1.1          0.1         setosa    \n",
       "87  6.5          3.2         5.1          2.0         virginica \n",
       "88  5.0          3.4         1.5          0.2         setosa    \n",
       "89  6.2          2.8         4.8          1.8         virginica \n",
       "90  6.7          3.1         5.6          2.4         virginica \n",
       "91  5.8          4.0         1.2          0.2         setosa    \n",
       "92  4.6          3.1         1.5          0.2         setosa    \n",
       "93  7.2          3.6         6.1          2.5         virginica \n",
       "94  6.7          3.1         4.4          1.4         versicolor\n",
       "95  5.0          3.5         1.6          0.6         setosa    \n",
       "96  7.7          2.6         6.9          2.3         virginica \n",
       "97  6.0          3.0         4.8          1.8         virginica \n",
       "98  6.7          3.3         5.7          2.5         virginica \n",
       "99  6.2          2.9         4.3          1.3         versicolor\n",
       "100 6.3          3.3         6.0          2.5         virginica "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "train_ind <- sample(seq_len(nrow(iris)), size = 100)\n",
    "iris[train_ind,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks complicated, but it's not. We can take this piece by piece starting with the inner most part `seq_len(nrow(iris))`. All this is doing is creating a sequence of numbers from 1 to the number of rows in the iris data frame, 150. Then we call the `sample()` function and specify that we only want 100 numbers returned that are sampled randomly from the sequence we just created. We call this sequence of randomly sampled numbers `train_ind`, as we will use these to reference these indexes on the iris data frame, which we can then use as a training set of data. The `set_seed(1)` just makes the the sample replicable.\n",
    "\n",
    "**Activity 1**: *Create a training data frame by using the `train_ind` sequence on the iris data frame. Call this frame `train`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code for Activity 1 goes here\n",
    "# *****************************\n",
    "train <- iris[train_ind,]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we need to make a testing frame from those indexes that are not in the `train_ind` sequence. In `R` we can do this with the following notation `dataframe[-sequence,]` where the `dataframe` is our data frame object we are working with, and `sequence` is the sequence of indexes. The \"`-`\" sign specifies that we don't want those indexes. \n",
    "\n",
    "**Activity 2**: *Create a testing data frame from the rest of the data not included in `train`. Call this data frame `test`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code for Activity 2 goes here\n",
    "# *****************************\n",
    "test <- iris[-train_ind,]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have both the training and testing sets defined, we can specify our formula. We will begin predicting Species by all of the features. Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just in case defining these two data frames was giving you trouble...\n",
    "train <- iris[train_ind,]\n",
    "test <- iris[-train_ind,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frmla <- Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can train our model on our training set using our formula to specify our target and inputs. We will call this model `m`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Naive Bayes Classifier for Discrete Predictors\n",
       "\n",
       "Call:\n",
       "naiveBayes.default(x = X, y = Y, laplace = laplace)\n",
       "\n",
       "A-priori probabilities:\n",
       "Y\n",
       "    setosa versicolor  virginica \n",
       "      0.34       0.44       0.22 \n",
       "\n",
       "Conditional probabilities:\n",
       "            Sepal.Length\n",
       "Y                [,1]      [,2]\n",
       "  setosa     4.958824 0.3518857\n",
       "  versicolor 5.904545 0.5567570\n",
       "  virginica  6.245455 0.8442318\n",
       "\n",
       "            Sepal.Width\n",
       "Y                [,1]      [,2]\n",
       "  setosa     3.341176 0.4899730\n",
       "  versicolor 2.809091 0.2543134\n",
       "  virginica  2.909091 0.3884702\n",
       "\n",
       "            Petal.Length\n",
       "Y                [,1]      [,2]\n",
       "  setosa     1.458824 0.1371989\n",
       "  versicolor 4.304545 0.4412938\n",
       "  virginica  5.345455 0.5645594\n",
       "\n",
       "            Petal.Width\n",
       "Y                 [,1]       [,2]\n",
       "  setosa     0.2294118 0.07717436\n",
       "  versicolor 1.3181818 0.20385888\n",
       "  virginica  1.9545455 0.23393861\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m <- naiveBayes(frmla, data = train)\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the predict function on our testing data to assess the performance of the model. But this time we are going to create a table that shows the number of points properly classified and misclassified.\n",
    "\n",
    "To do this, we can call the `predict()` function and specify the dataset we want it to predict. But be careful, the dataset that you test on must have the same variables as the input of the formula. It is that reason that the `test[,-5]` below removes the 5th column, the `Species` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            \n",
       "             setosa versicolor virginica\n",
       "  setosa         33          0         0\n",
       "  versicolor      0         27         2\n",
       "  virginica       0          1        37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(predict(m, test[,-5]), test[,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it only 2 points were misclassified! Not bad. \n",
    "\n",
    "But remember back to the Decision Tree lab notebook in `R` where it said it only used petal length, petal width, and sepal length in its model? This was the same thing that we found in the Decision Trees practice notebook. \n",
    "\n",
    "How would performance change if we took this variable out?\n",
    "\n",
    "**Activity 3**: *Prune the formula and take out the `Sepal.Width` variable. Call this new formula `prune_frmla`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for Activity 3 goes here\n",
    "# *****************************\n",
    "prune_frmla <- Species ~ Sepal.Length + Petal.Length + Petal.Width \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 4**: *Now create a new model using `prune_frmla` with the training data set. Call this new model m2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Naive Bayes Classifier for Discrete Predictors\n",
       "\n",
       "Call:\n",
       "naiveBayes.default(x = X, y = Y, laplace = laplace)\n",
       "\n",
       "A-priori probabilities:\n",
       "Y\n",
       "    setosa versicolor  virginica \n",
       "      0.34       0.44       0.22 \n",
       "\n",
       "Conditional probabilities:\n",
       "            Sepal.Length\n",
       "Y                [,1]      [,2]\n",
       "  setosa     4.958824 0.3518857\n",
       "  versicolor 5.904545 0.5567570\n",
       "  virginica  6.245455 0.8442318\n",
       "\n",
       "            Petal.Length\n",
       "Y                [,1]      [,2]\n",
       "  setosa     1.458824 0.1371989\n",
       "  versicolor 4.304545 0.4412938\n",
       "  virginica  5.345455 0.5645594\n",
       "\n",
       "            Petal.Width\n",
       "Y                 [,1]       [,2]\n",
       "  setosa     0.2294118 0.07717436\n",
       "  versicolor 1.3181818 0.20385888\n",
       "  virginica  1.9545455 0.23393861\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code for Activity 4 goes here\n",
    "# *****************************\n",
    "prf<- naiveBayes(prune_frmla, data = train)\n",
    "prf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is `m2` a better, worse, or about the same given our testing data set?\n",
    "\n",
    "**Activity 5**: *Find the number of misclassified points using the `m2` model and the testing data set. Remember, when predicting on the testing data, remember that you will have to remove both the target variable and the `Sepal.Width` variable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            \n",
       "             setosa versicolor virginica\n",
       "  setosa         33          0         0\n",
       "  versicolor      0         27         1\n",
       "  virginica       0          1        38"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code for Activity 5 goes here\n",
    "# *****************************\n",
    "table(predict(prf,test[,-c(2,5)]), test[,5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
