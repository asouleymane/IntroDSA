{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "In this lab, we are going to focus on loading our data about baseball players into a database. Why use a database instead of files? Conceptually, we do this when we want to enforce rules on the structure of the data so that issues of cleanliness, inconsistency and missing data are identified prior to our attempts to do analysis. \n",
    "\n",
    "Database management systems provide well defined structure for data. They also have the advantage of giving us standard mechanisms for extracting data: \"Structured Query Language\", or \"SQL. If  you have not used SQL before, it will require a little adjustment. Once you are familiar with it, however, you will find SQL intuitive and portable.\n",
    "\n",
    "As you learned in the previous lab, Data Carpentry is often required to transform your messy data into a useable structure. \n",
    "\n",
    "Data Carpentry is a fancier, more elegant term for \"Data Janitorial\" work. Most of us would rather be carpenters than janitors. If you spend any time around children, you recognize that life *requires* more janitorial work than carpentry. And so it is with data science. But carpentry *sounds* [1] better, so we're going to use that [2]. \n",
    "\n",
    "Using a database allows you to store your transformed and cleaned data into a reusable, structured, and semantically labelled format.\n",
    "\n",
    "You can then access this data in the future using structured query language (SQL). \n",
    "\n",
    "## Procedure\n",
    "\n",
    "1. Inspect data, develop semantically structured data storage (i.e., database schema)\n",
    "2. Develop data transformations, cleaning, and re-organizations\n",
    "3. Push data into the database\n",
    "\n",
    "__NOTE:__ A quick review of the *Database and SQL Bootcamp* may be useful at this time.\n",
    "In JupyterHub, this was deployed for you as **BC-SQL**.\n",
    "\n",
    "----\n",
    "\n",
    "## Inspect\n",
    "\n",
    "For this lab, we are going to use relatively clean data that is in nice comma separated values (CSV) format.\n",
    "Typically, the data requires data carpentry activities, but for the sake of a more simple collection of samples and discussion we are going to start with easy data.\n",
    "\n",
    "To work with our data files we are going to use Pandas and Numpy\n",
    "\n",
    "[1]: https://www.youtube.com/watch?v=pMRUszqMVM8 \"Replacements: Waitress in the Sky Song\"\n",
    "[2]: http://www.azlyrics.com/lyrics/replacements/waitressinthesky.html \"Replacements: Waitress in the Sky Lyrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "players = pd.read_csv('../../../datasets/baseball-databank/data/Master.csv')\n",
    "teams = pd.read_csv('../../../datasets/baseball-databank/data/Teams.csv')\n",
    "batting = pd.read_csv('../../../datasets/baseball-databank/data/Batting.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__No Output Expected__\n",
    "\n",
    "Now we have loaded our three files into the variables: *players*, *teams*, and *batting*.\n",
    "Each of these variables is a Pandas **dataframe**.\n",
    "As you have often done before, we can preview the data with the *head()* method called on the **dataframe** variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "As we can see, the CSV files are tabluar data files. \n",
    "Note, in each case the tables cannot fit within the display and the *ellipse* (...) is used to denote columns that are removed from the display.\n",
    "Do you recall how to view the columns of a dataframe?\n",
    "Like all things python, there are a few ways to do this.\n",
    "We will just use the list function to inspect the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(players)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get to see all the columns of the dataframe this way\n",
    "\n",
    "__Your Turn__  \n",
    "In the cell below, add code to list the columns of the teams and batting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add your code in this cell\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We know the columns... now what?\n",
    "\n",
    "## Database Design\n",
    "\n",
    "Now that we know the columns, we need to contemplate how we will use a database to structure the data.\n",
    "Recall from your previous database knowledge, or the bootcamp, that a relational database is an organized set of __tables__ (aka *Relations*).\n",
    "\n",
    "Recall that __tables__ are a structured set of columns with semantic meaning, a particular data type, and constraints on validity.\n",
    "We are assuming that you have a little domain knowledge in Baseball to interpret the semantics of these column labels.\n",
    "For example, the *batting* column *RBI* we can expect to be *Runs Batted In*.\n",
    "\n",
    "#### REVIEW : SQL : Create Table\n",
    "```SQL\n",
    "CREATE TABLE table_name (\n",
    "  col_a_name col_a_datatype, \n",
    "  col_b_name col_b_datatype, \n",
    "  col_c_name col_c_datatype, \n",
    "  ...\n",
    "  PRIMARY KEY(list_of_columns)\n",
    ");\n",
    "```\n",
    "**REFERENCE LINK** [SQLite Create Table](https://www.sqlite.org/lang_createtable.html)\n",
    "\n",
    "### Column Data Types\n",
    "\n",
    "Databases support very rigid data typing, however SQLite permits looser *type affiinty* based on storage classes.\n",
    "From the SQLite documentation: \n",
    "```\n",
    "Each column in an SQLite 3 database is assigned one of the following type affinities:\n",
    "    TEXT\n",
    "    NUMERIC\n",
    "    INTEGER\n",
    "    REAL\n",
    "    BLOB\n",
    "```\n",
    "\n",
    "For this exercise, we will limit our storage columns to one of:\n",
    " 1. **TEXT** - Character strings\n",
    " 2. **INTEGER** - whole numbers, no decimal places\n",
    " 3. **REAL** - floating point numbers with decimal places\n",
    "\n",
    "\n",
    "**REFERENCE LINK** [SQLite Column Data Types](https://www.sqlite.org/datatype3.html)\n",
    "\n",
    "So, how can we exam in a programmatic way the data types as interpreted by Pandas?  \n",
    "Recall that a dataframe provides column access via __dataframe__[*column_name*], and the column is an object that holds a list of values and the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dtype is the Data Type of the column that is referenced by name in the square brackets\n",
    "players['birthYear'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that bithYear is a floating point number, which above we refer to as a **REAL**\n",
    "\n",
    "Since we have python at our fingertips... lets programmatically inspect the colunms and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remember above, the list command did an inspection and \n",
    "# got a list of column names in the data frame!\n",
    "for columnName in list(players):\n",
    "    print(\"Column {} is a {}\".format(columnName, players[columnName].dtype))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above should look similar to:\n",
    "```\n",
    "Column playerID is a object\n",
    "Column birthYear is a float64\n",
    "...\n",
    "Column bbrefID is a object\n",
    "```\n",
    "\n",
    "The **object** datatype we will interpret as **TEXT** for the data base.\n",
    "Scroll back up to when we previewed the data files, does this seem reasonable?  \n",
    "Let us check, just to be sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players['playerID'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems OK!\n",
    "You should typically check every column that you are going to load into the database.\n",
    "\n",
    "Once you are ready to create a table, we can write the create table statement:\n",
    "\n",
    "```SQL\n",
    "CREATE TABLE players (\n",
    "  playerID TEXT,\n",
    "  birthYear REAL,\n",
    "  ...\n",
    ");\n",
    "```\n",
    "\n",
    "Can we automate this for a generic CSV to SQL Table?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "This segment of code shows the use of Python to automate the generation of SQL Create table from a Pandas dataframe.\n",
    "\n",
    "__Note:__ the special escape characters for *newline* (''\\n'') and *tab* (''\\t'') are used to generate visually pleasing SQL, they are not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Begin the create table statement\n",
    "createTableStmt = \"CREATE TABLE players (\\n\"\n",
    "\n",
    "# Build a translate from Panda to SQL type\n",
    "dtype2SQL = {'object' : 'TEXT', 'float64' : 'REAL', 'int64' : \"INTEGER\"}\n",
    "# Note, the int64 ?  That came from the teams and batting dataframes\n",
    "\n",
    "\n",
    "columnList = list(players)\n",
    "\n",
    "for columnName in columnList:\n",
    "    pandaType = str(players[columnName].dtype) # Note, we need to force the conversion of the type name to a string\n",
    "    sqlDataTypeStr = dtype2SQL[pandaType]      # Then we look up the SQL type Desired\n",
    "    #\n",
    "    #  Construct a Column Spec \n",
    "    #  col_name col_dtype , \n",
    "    createTableStmt += \"\\t{} {},\\n\".format(columnName, sqlDataTypeStr)\n",
    "    #\n",
    "    # NOTE:  the string1 += string2 appends string2 to the end of string 1, e.g., \"ABC\"+=\"XYZ\" results in \"ABCXYZ\"\n",
    "    #\n",
    "    \n",
    "    \n",
    "# Note, the last column has a trailing comma, so we can now add a Primary Key specification\n",
    "# If this is not suitable for the data file you have, you will need to make adjustments \n",
    "# such as removing the last comma before closing off the table.\n",
    "createTableStmt += \"\\tPRIMARY KEY({})\\n\".format(columnList[0])\n",
    "\n",
    "\n",
    "\n",
    "# Close off the Create Table Statement\n",
    "createTableStmt += \");\"\n",
    "\n",
    "print(len(createTableStmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "## \n",
    "## Now lets modularize this:\n",
    "##\n",
    "###################################\n",
    "def dataframe2CreateTable(dataFrame, tableName = \"WHATS_MY_NAME\",useFirstColumnAsPK=True):\n",
    "    '''\n",
    "    This function inspects a Panda Dataframe and converts it to \n",
    "    a SQL Create Table Statement String\n",
    "    \n",
    "    Arguments:\n",
    "       dataFrame : a panda dataframe with column headers\n",
    "       tableName : a valid SQL table name\n",
    "       useFirstColumnAsPK : Use the first column as a primary key, default=True\n",
    "    \n",
    "    Returns : a Create Table tableName string\n",
    "    '''\n",
    "    createTableStmt = \"CREATE TABLE {} (\\n\".format(tableName)  # used the format to splice in the table name \n",
    "    dtype2SQL = {'object' : 'TEXT', 'float64' : 'REAL', 'int64' : \"INTEGER\"}\n",
    "    columnList = list(dataFrame)  # Replaced players from code with function variable\n",
    "    \n",
    "    for columnName in columnList:\n",
    "        # NOTE: Some of the columns start with a number, this is not valid column naming\n",
    "        # in most databases;  so the next four lines detect and fix\n",
    "        if (columnName[0].isdigit()):\n",
    "            sqlColumnName = \"n\"+columnName   # we will just prepend the letter 'n' (for number)\n",
    "        else:\n",
    "            sqlColumnName = columnName\n",
    "\n",
    "        pandaType = str(dataFrame[columnName].dtype) # Note, we need to force the conversion of the type name to a string\n",
    "        sqlDataTypeStr = dtype2SQL[pandaType]      # Then we look up the SQL type Desired\n",
    "        createTableStmt += \"\\t{} {},\\n\".format(sqlColumnName, sqlDataTypeStr)\n",
    "    # END OF FOR EACH COLUMN\n",
    "    \n",
    "    # Close off the Create Table Statement with the PK\n",
    "    if (useFirstColumnAsPK):\n",
    "        createTableStmt += \"\\tPRIMARY KEY({})\\n\".format(columnList[0])\n",
    "    else: # replace last comma with a space, note it's minus 2 because -1 is the newline\n",
    "                                          # This is the substring access \n",
    "                                          # see : https://docs.python.org/3/tutorial/introduction.html#strings\n",
    "        createTableStmt = createTableStmt[:len(createTableStmt) -2] + \"\\n\"\n",
    "    createTableStmt += \");\"\n",
    "    \n",
    "    return  createTableStmt\n",
    "# ------- END OF dataframe2CreateTable\n",
    "\n",
    "\n",
    "# Invoke\n",
    "help(dataframe2CreateTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting our DB creation together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We are going to write a SQLite DB\n",
    "import sqlite3\n",
    "\n",
    "playersCreateTableStmt = dataframe2CreateTable(dataFrame = players, tableName = 'players')\n",
    "teamsCreateTableStmt = dataframe2CreateTable(dataFrame = teams, tableName = 'teams', useFirstColumnAsPK=False)\n",
    "battingCreateTableStmt = dataframe2CreateTable(dataFrame = batting, tableName = 'batting', useFirstColumnAsPK=False)\n",
    "\n",
    "\n",
    "print(playersCreateTableStmt)\n",
    "print(teamsCreateTableStmt)\n",
    "print(battingCreateTableStmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** In reality, some of the column data types such as year and counting statitics should be INTEGER type.\n",
    "However, for this example we will just move forward.\n",
    "There are ways to manipulate the panda dataframe to move the data into a better aligned colunm data type.\n",
    "We will leave that as a thought exercise for now.\n",
    "\n",
    "__WARNING__ : \n",
    "Please note, that when we first connect to a database using SQLite and it does not exist, it gets created for us.  \n",
    "This *friendly* behavior can be REALLY OCNFUSING on that day in the future when you have a file path wrong on a database you previous have populated and it looks empty to your code.  \n",
    "\n",
    "__REFERENCE__ : [Python SQLite3](https://docs.python.org/3/library/sqlite3.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Below is a pathname = ../baseball.db \n",
    "# The path is broken into elements around the '/' character (i.e., \"forward slash\" because it leans forward)\n",
    "# The first path element is the '..'  which is interpreted as the parent directory/folder. \n",
    "#        Look at the URL.  File file is named: --- module3/labs/database_loading.ipynb\n",
    "#        This file is in a folder named labs, which is in a folder named module3.\n",
    "#        This path name is therefore for module3/labs/../baseball.db\n",
    "#                   ... which is equivalent to module3/baseball.db\n",
    "#        We are putting the file there so it is accesible during exercises\n",
    "databaseFilename = '../baseball.db'\n",
    "\n",
    "# Just because we are creating this file here\n",
    "#  we will remove it incase you re-run the cell\n",
    "if os.path.exists(databaseFilename):\n",
    "    os.remove(databaseFilename)\n",
    "    \n",
    "# Open / Create the baseball.db database file.\n",
    "connection = sqlite3.connect(databaseFilename)\n",
    "\n",
    "# SQLite uses a cursor to track and manage and group operations.\n",
    "cursor = connection.cursor()\n",
    "# A cursor is a database execution context that provides isoation between \n",
    "#  the operations in the cursor and other operations that are happening\n",
    "#  simultaneously.\n",
    "# These operations can be undone by cancelling (i.e., ROLLBACK) the transaction before the cursor context \n",
    "#  is committed\n",
    "\n",
    "# Create tables\n",
    "cursor.execute(playersCreateTableStmt)\n",
    "cursor.execute(teamsCreateTableStmt)\n",
    "cursor.execute(battingCreateTableStmt)\n",
    "\n",
    "# Save (commit) the changes\n",
    "connection.commit()\n",
    "\n",
    "# We can also close the connection if we are done with it.\n",
    "# Just be sure any changes have been committed or they will be lost.\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NO OUTPUT EXPECTED__\n",
    "\n",
    "\n",
    "### Did this work?\n",
    "You can either open the file using the command line as you may hav done in the bootcamp.\n",
    "\n",
    "![Command Line Image](../images/SQLite3_baseball_db_players_schema.png)\n",
    "\n",
    "... or we can use SQL and Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Did this actually work?\n",
    "#  Open the DB file\n",
    "databaseFilename = '../baseball.db'\n",
    "connection = sqlite3.connect(databaseFilename)\n",
    "\n",
    "# Select the list of tables from the SQLite Engine Catalog for the database file\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Iterate through all the rows back, where the first column is the table name\n",
    "for table_name in tables:\n",
    "    print(table_name[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### FINALLY ... we get to load the data\n",
    "\n",
    "What this entails is iterating through the dataframe and inserting the values into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "databaseFilename = '../baseball.db'\n",
    "connection = sqlite3.connect(databaseFilename)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "for row in players.itertuples(index=False, name ='None'):\n",
    "    cursor.execute('INSERT INTO players VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)',row)\n",
    "\n",
    "# Save (commit) the changes\n",
    "connection.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__REFERENCE:__ [itertupples : Iterate Through Dataframe Rows, each row a tuple](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples)\n",
    "\n",
    "__How to see the data from the database prompt__\n",
    "![Select 5 players](../images/SQLite_baseball_select_5_players.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "databaseFilename = '../baseball.db'\n",
    "connection = sqlite3.connect(databaseFilename)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "batting.fillna(value=0) # Fill NaN values\n",
    "\n",
    "# Or stand on the shoulders including giants\n",
    "cursor.executemany('INSERT INTO batting VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)',\n",
    "                   batting.itertuples(index=False, name ='None'))\n",
    "\n",
    "\n",
    "# Save (commit) the changes\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the things we have not addressed is dealing with the ''NaN'' values in many cells of the data frames.\n",
    "\n",
    "\n",
    "__REFERENCE:__ Now that we did all this in a drawn out fasion, see [SQL Loading from Pandas](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html)  \n",
    "See Also: [SQLAlchemy](http://www.sqlalchemy.org/)\n",
    "\n",
    "\n",
    "__REMEMBER__ : This lab used clean CSV files that were mostly straight foward. Often, data carpentry activities requires the efforts of the previous lab as well as this lab.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE YOUR NOTE BOOK\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
